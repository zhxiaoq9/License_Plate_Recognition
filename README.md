# 基于OpenCV的车牌识别技术
---
[TOC]

##	简介

### 开发环境
*	平台：Windows7
*	OpenCV版本：OpenCV 2.9
*	开发环境：Visual Studio 2013

### 车牌识别步骤
车牌识别的过程如下图所示
```flow
st=>start: 预处理
e=>end: 结束
op1=>operation: 车牌区域提取
op2=>operation: 车牌字符提取
op3=>operation: 车牌字符分割
op4=>operation: 车牌字符识别

st(right)->op1(right)->op2(right)->op3(right)->op4(right)->e
```

这些步骤的主要工作分别为：  
*       预处理
        预处理的作用是去除光照等因素的干扰，弱化背景突出显示车牌区域。

*	车牌区域提取

	通过一系列图像增强与模糊手段突出车牌区域并得到车牌区域的大致位置。本文主要使用了轮廓检测结合形态学处理的方法。

*	车牌字符提取

	从得到的车牌区域中去除边框与铆钉，然后进行去噪与二值化等处理，得到二值化的车牌图像。本文主要使用了基于纹理特征的方法。

*	车牌字符分割

	定位每个字符在车牌区域中的位置并提取出来。本文主要采用了基于投影的方法。

*	车牌字符识别

	得到字符后需要对这些字符进行匹配分析，知道提取的字符是什么，从而完成最终的车牌识别过程。本文主要采用了基于神经元的方法。

## 预处理
预处理的过程是对图像进行噪声消除以及增强车牌区域的过程，这里预处理的过程如下图所示。
```flow
st=>start: 读入彩色图像
e=>end: 得到Canny检测后的图像
op1=>operation: 区域生长
op2=>operation: 转为灰度图
op3=>operation: 中值滤波
op4=>operation: Canny边缘检测

st(right)->op1(right)->op2->op3(right)->op4(right)->e
```
### 区域生长
区域生长法是一种图像分割算法，通过这种方法可以将具有相同特征的联通区域分割出来。区域生长法的好坏取决于以下三点。
1. 种子点的选取
种子点的选取方法通常是按照要分割的感兴趣区域特点选取的。
2. 生长准则
一般情况下的生长准则是在种子点出进行8邻域或4邻域扩展，当邻域中像素点灰度值与种子点灰度值的差小于某个阈值T时就可以合并到同一个区域。
3. 终止条件
通常不再有新的像素点合并时生长停止。

> **区域生长：**在图像中选择一个像素点作为种子点（即生长的起点），然后将其邻域中具有与其相似性质的像素点与其合并成同一个区域。然后将这些新加入的像素点作为新的种子点重复上面的过程直到不再有新的像素点加进来。

本文中的区域生长法是调用OpenCV的默认函数floodFill实现的，而种子点的选取规则是：先将彩色图像从RGB空间转到HSV空间，然后在HSV图像中的中间部分（将图像的行列分别分为四份，由中间两份对应面积决定的区域，因为车牌通常不会在图像边缘）寻找蓝色的点（车牌底色一般是蓝色的，蓝色点的HSV范围可以调整），并将最后一个蓝色的点作为种子点

### 其它
在用区域生长完成分割后就可以将车牌区域凸显出来，然后将分割后的图像转换为灰度图。为了去除噪声的影响需要进行滤波处理。然后通过Canny边缘检测检测出车牌边缘等待做进一步处理。

## 车牌区域提取
本文车牌区域处理主要采取形态学处理与轮廓检测的方法。流程如下图所示。
```flow
st=>start: Canny检测后的图像
e1=>end: 得到车牌区域
e2=>end: 检测失败
op1=>operation: 轮廓检测
cond1=>condition: 提取车牌
cond2=>condition: 再提取车牌
op2=>operation: 形态学处理
op3=>operation: 再轮廓检测

st->op1->cond1
cond1(yes)->e1
cond1(no)->op2(right)->op3(right)->cond2
cond2(yes,)->e1
cond2(no)->e2
```
### 提取车牌的方法
在经过预处理后，一般情况下车牌边缘就可以用Canny算法检测出来。由于车牌的边缘是有一定长宽比的矩形，而且具有一定的面积。所以，在得到边缘图像后可以检测图像中的长方形并计算其长宽比和面积，根据这两者判断是否有符合要求的长方形，如果有那么就可以把这个长方形所在区域视为车牌所在区域。

> **注意：** 一般情况下车牌的长宽比是不随图像大小变化的，但是面积会。为了排除图像大小对面积判断造成的影响需要将输入的图像统一调整到一个固定的大小。但是*`目前的设计中是没有考虑图像大小的影响的`。*
>> 本文中车牌的长宽比暂时设置为2-5之间，而面积设置为2900-9000。

### 为什么要做形态学处理
有时候，在预处理效果比较好的情况下车牌的边缘可以通过Canny算法检测出来。但是有时候由于预处理效果不理想，车牌的边缘并不能检测出来，而是只检测出了车牌中的字。这是就需要对Canny检测后的图像做形态学处理，将这些字组成一个连通域，然后再做轮廓检测即可将车牌区域的轮廓检测出来。
> 本文中形态学处理步骤是经过多次试验得到的。对于检测到的Canny图像先做两次闭运算，然后做三次膨胀运算，最后再做一次闭运算与开运算。先做闭运算的作用是将字之间的缺口连接起来，三次膨胀操作一方面是填充字中的区域，另一方面是因为通过这种方法检测到的区域比能直接检测到轮廓边缘的情况检测到的面积小，这样可以适当增加一下面积。再做闭运算是最后调整图像中的空洞。最后的开运算是为了断开连通域与其它元素可能的细小连接。


本文中轮廓检测是通过调用OpenCV中的findContours函数实现的，检测后可以通过drawContours函数将矩形画出来。

## 车牌字符提取
得到车牌位置后就可以将车牌图像从图中抠出单独堆车牌做处理。字符提取的作用就是对车牌做处理进一步确定字符所在区域并且将各个字符凸显出来。它的主要任务有以下几个。
* 去除车牌边框与铆钉
* 突出字符

字符提取的流程如下图所示。
```flow
st=>start: 车牌彩色图像
e=>end: 二值车牌图像
op1=>operation: 灰度化
op2=>operation: 中值滤波
op3=>operation: 二值化
op4=>operation: 前景背景交换
op5=>operation: Canny检测
op6=>operation: 去除边框和铆钉

st->op1(right)->op2->op3(right)->op4->op5(right)->op6->e
```
### 预处理
预处理包含了从灰度化到Canny检测的这些步骤。由于车牌的面积相对较小，所以受光照不均匀的影响一般较小，将其灰度化后做下简单的中值滤波即可。

这里主要讲的是二值化的过程，由于字符提取的一个任务就是突出字符区域，二值化效果的好坏直接影响字符的质量。本文采用了OTSU（最大类间方差法），因为OTSU算法是一种自适应的分割算法，虽然它对噪声比较敏感，但是车牌图像中的噪声往往不是很大。

> **OTSU基本原理：**OTSU算法的基本思想就是将一张图片通过阈值T分成前景色与背景色两个部分，通过统计直方图并比较前景区域与背景区域的差别，一直改变T的值使得得到的前景与背景的差最大。这时所对应的阈值T就时最终用来二值化的阈值。

将图像二值化后，有时候二值化的图像背景是黑色而前景是白色，但也会出现背景是白色而前景是黑色的情况。当出现后者的情况时需要将图像取反得到背景为黑色的图像。因为对车牌来说，二值化后的前景基本只是车牌中的字符，而车牌字符所占面积一般是不会超过车牌面积50%的，加上边框与铆钉的影响，设置阈值为45%。即如果检测的二值化图像中黑色部分的面积大于65%那么就将二值化的图片前景与背景交换。

### 边框与铆钉的去除
本文采用统计二值化图像跳变次数的方法来去除边框与铆钉来进一步确定字符所在区域。这里以水平检测为例。

边缘检测后的图像中只有黑白两种颜色。对车牌图像，我们逐行检测图像中的每一行像素的跳变次数（从0变255或从255变0），由于多个字符的存在，在字符区域所在的行跳变次数会明显多于那些没有字符区域的跳变次数。这里设置每行的跳变次数阈值为13，在检测时如果跳变次数小于13，那么就将这行丢弃，如果连续三行的跳变次数大于等于13，那么就把它划分到字符所占区域。

对于列的检测也是同样的方法，不同的是对每列进行检测时，字符所占区域的跳变次数分布范围比较大。如果这列是数字1，那么可能只有两次跳变，而如果是是汉子的话就会跳变多次。这里将阈值设为2。即如果这列跳变次数小于等于2那么就不是字符区域，反之则是字符区域。

> **注意：**对行检测时要连续三行的跳变次数满足要求是才确定是字符区域，而对列检测时检测到一次就可以了。因为对列检测时如果也是连续多列满足要求才算字符区域的话那么很可能会将数字1也给去掉。

完成上述步骤后，就可以得到更精确的车牌图像了。

## 车牌字符分割
车牌字符分割的作用是将车牌中的一个个字符单独提取出来。主要任务就是确定每个字符的左右边界。中国大陆的车牌一般都有七个字，第一个一般是汉子，表示所在省份。其它6个都是数字加字母的形式，并且其中没有O和I，避免与0和1的分别。需要注意的是在第二与第三个字符之间通常会有一个圆点来分隔，这也是要去掉的。本文车牌字符分割的步骤如下图所示。
```flow
st=>start: 车牌二值图像
e=>end: 得到最后的字符
op1=>operation: 统计每列前景点数目
op2=>operation: 根据阈值确定字符边缘
op3=>operation: 确定分割的字符是否是车牌字符

st(right)->op1(right)->op2(right)->op3(right)->e
```
### 确定字符边界
车牌二值图像的前景色是车牌中的字符或者用于分开字符的点或者一些其它噪声干扰。一般情况下如果某一列没有字符的话那么这一列所有的像素点都应该是背景色（即黑色），考虑到噪声的干扰等情况，可以设置一阈值T来判定某列是否属于字符区域。

首先对二值车牌图像统计每列前景色点的数目，如果这个数目大于阈值T（这里设置为1）说明此列在字符区域（设置为真），否则就不在（设置为假）。然后根据每列的真假情况确定字符的开始位置与结束位置。

### 确定是否属于车牌字符
由于车牌字符的高宽比通常在一定范围内（2左右），而且除了数字1之外，车牌的宽度基本上不可能只占一连个像素点。本文中将车牌字符的高宽比设置为1.5-5，如果高宽比在这个范围内那么就认定是车牌字符。如果高宽比小于1.5那么就不是，如果大于5的话那么说明这可能是数字1的特殊情况（因为数字1宽度是可以很小的）。针对这种情况的解决方法是，如果发现高宽比大于5的区域，那么就从这个字符宽度范围内选取一列并统计这列的前景像素点的数目。如果这个数大于这列所有像素点的百分之90以上那么说明这个数字为1，否则就不是。（数字1在列上的前景色数目是比较多的）。通过上述方法基本上就可以将噪声和用于分隔车牌字符的中间点去掉了。

## 车牌字符识别
分割出一个个字符后就要识别这些字符都是什么。常用的车牌字符识别由基于模板匹配的算法与基于神经网络的方法等。本文中采用基于神经元网络的方法，之后可能会改用基于SVM（支持向量机）的方法。

### 神经网络基本理论
[神经元网络][ANN]是类比人类神经元的方法，它的基本单元如下图所示。

![](http://deeplearning.stanford.edu/wiki/images/thumb/3/3d/SingleNeuron.png/300px-SingleNeuron.png)

其中x1,x2,x3是输入，而+1是偏置项。h<sub>w,b</sub>(x)是输出，他们之间的关系可以表为：

$h_{W,b} (x) = f(W^T x) = f(\sum_{i=1}^{3} W_{i} x_{i} + b)$
其中$f(x)$叫做激活函数，其表达式一般为：
$f(x) = \frac{1}{1+e^{-z}}$ 

整个神经网络的模型如下图所示。
![](http://deeplearning.stanford.edu/wiki/images/thumb/9/99/Network331.png/400px-Network331.png)
上图中的神经元有三个层，输入层，隐层，输出层，更复杂一点的神经元可以有多个隐含层，也可以有多个输出层。
> **偏置项：**正如人大脑的神经元一样，只有在外界刺激达到一定水平时人的神经元才会处于激活状态，上面的偏置项就可以看做是这个阈值，只是这里将它定义成了1。

神经元是一种有监督学习算法，需要先经过训练才行。整个神经元训练与工作流程为：
1. 取一组标准的训练样本并给定对应分类标签，根据样本决定其特征向量输入神经元网络。
2. 神经元网络会根据输入的特征向量以及初始条件计算输出并与标签做比较计算出误差，如果这个误差满足要求那么就结束训练，否则就根据误差的值重新调整各个权重，这个过程叫做反向传播。
3. 调整权重后重新计算输出并判断误差是否满足要求，知道满足要求后结束。

训练结束后就可以得到神经元网络的结构与各个神经元单元的权重数据，这时如果拿到一个未分类的样本只需要将样本的特征向量输入神经元网络，根据事先计算好的权值计算输出即可。神经元的输出范围一般是0到1或者-1到1，表示样本是正样本的概率。如果是0到1的情况，那么一般只要输出大于0.5的话就认为是正样本，反之为负样本。如果是-1到1的话那么只要输出大于0就认为是正样本。

### 字符识别库
本文使用的字符识别库与下面链接对应博客的识别库是一样的，只是样本集比较小。
博客地址：http://blog.jobbole.com/84234/
或者也可以直接从下面的网址下载。
百度云盘：http://pan.baidu.com/s/1mgLUWBm

### 特征向量的选取
本文的特征向量考虑了图像的梯度分布特征与灰度分布特征两个方面。
#### 梯度分布特征
对训练样本，首先统一将图像调整到16*8大小，然后用Sobel水平与垂直边缘检测算子计算水平与垂直方向上的边缘。然后将每张图像分成4*4大小的8张图像，并计算每张子图像像素之和与整个边缘检测后的图像像素和的比值，将其作为特征向量。那么梯度分布特征就有8*2=16个特征。
#### 灰度统计特征
灰度统计特征中需要将输入图像统一调整到8*4大小，然后将图像展成一行，以每个像素点的灰度值作为特征。这样灰度统计特征会产生32个特征。

所以，一幅图像总共有16+32=48个特征，将它们放在一个数组中，其组织方式如下所示。
{{X方向梯度分布特征，Y方向梯度分布特征}重复八次，灰度统计特征32个}
> **注意：**X方向与Y方向的梯度分布特征是交叉存放的。

### 训练方法
本文中的神经元网络分为三层。第一层为输入层有48个输入，用来输入48个特征。第二层是隐含层，这个数目需要在训练的过程中进行调整，目前设置的值为58。第三层是输出层，目前的车牌字符识别不考虑中文汉字的识别，所以输出可能为0-9的数字或者A-Z的字母（不包含O和I）共34个，所以输出层有34个输出。

因为每个字符的样本总共有50个，所以训练时拿出40个作为训练样本，10个作为测试样本。本文采用反向传播（BACKPROP）算法进行训练，每次训练10个样本，当训练次数达到5000次后者误差值小于0.01的时候停止训练。
在OpenCV中对应神经元的设置如下。
```opencv
//------------------------set trainning params------------------------//
CvANN_MLP_TrainParams params;
params.train_method = CvANN_MLP_TrainParams::BACKPROP;
params.bp_dw_scale = 0.1;
params.bp_moment_scale = 0.1;
params.term_crit = cvTermCriteria(CV_TERMCRIT_ITER+CV_TERMCRIT_EPS, 5000, 0.01);
//------------------------set trainning network------------------------//
CvANN_MLP ANN;
//set hidden layer to 58,we can get classification rate to 91%
int ar[] = { 48, 58, 34 };
Mat LayerSize(1, 3, CV_32S, ar);
ANN.create(LayerSize, CvANN_MLP::SIGMOID_SYM);  
```
### 测试结果
训练结束后可以拿测试样本来测试，目前对于使用的样本集来说能够达到的最高的正确率为91%，其各项参数与上面介绍的参数是一样的。

## 待改进的问题
虽然目前基本上完成了框架的搭建，但是仍有较多问题需要改进。
1. 代码输入前期进行预处理时并没有对图片做归一化处理，这对之后通过轮廓检测时设置矩形面积范围有很大影响。
2. 由于区域生长法是读入图片后的第一次处理，而且这次处理对车牌区域的增强影响极大。这一步处理不好那么只会基本上车牌区域是检测不出来的，所以这方面还需要改进。
3. 一张图片中可能会有多个车牌图像，而本文中的设计目前只能检测一个图像。
4. 在字符分割阶段，由于字符1的宽度比较小，可能会漏掉对字符1的检测。
5. 在字符分割阶段，由于图像中的车牌可能会发生倾斜，所以需要先进行倾斜校正。
6. 目前字符识别不支持中文的识别。
7. 在字符识别部分，实际上SVM算法可能会达到更好的效果，未来可以考虑使用这个算法。



[ANN]: http://deeplearning.stanford.edu/wiki/index.php/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C "神经元介绍" 

